[{"count": 26, "commit_pairs": {"BOOKKEEPER-588": {"fixed_bug_sha": "8e0bd2c3d81b522e97434d8646915f36422a104b", "parent_bug_sha": "45e7f08f6a88de2fbb2f23df4c15a88625edff5d", "commit_message": "BOOKKEEPER-588: SSL Support for Bookkeeper\n\n+ Merged changes from eoliville\n+ Mutual Authentication\n\nAuthor: kishorekasi <kkasiud1@gmail.com>\nAuthor: Kishore Kasi Udayashankar <kudayashankar@salesforce.com>\nAuthor: Kishore Udayashankar <kudayashankar@salesforce.com>\n\nReviewers: Sijie Guo <sijie@apache.org>\n\nThis patch had conflicts when merged, resolved by\nCommitter: Sijie Guo <sijie@apache.org>\n\nThis closes #183 from kishorekasi/BOOKKEEPER-588-kishore"}, "BOOKKEEPER-1102": {"fixed_bug_sha": "a5f8580f53464065243a9af038935f5893434166", "parent_bug_sha": "f581e030c79abbde81bf165603fccdb5e6a1d38a", "commit_message": "BOOKKEEPER-1102: Clarify BookieInfoReader and fix associated test flappers\n\nBookieInfoReader:\n\nThe previous syncronization logic wasn't really correct, and the logic\nat the top of the method was far more complicated than it needed to be.\nRestrict bookies to be non-null.  Restructure the code to simply use\nthe BookieInfoReader instance as a single lock.\n\nOne significant behavioral change is that we scan every bookie not in\nthe map, and we clear from the map bookies which returned an error.\n\nAlso, explicitely cache the most recent bookie set reported by the\nBookieWatcher.  This eliminates the need to call into BookieWatcher\nfrom getReadWriteBookieInfo and the corresponding error path.  The\nperiodic scan continues to explicitely check.\n\nAnother departure is the addition of an explicit retry-on-error param to\ntrigger retry if any of the requests failed\n(getBookieInfoRetryIntervalSeconds).  We'll only retry the ones that\nactually failed (along with any new additions since the last run).  This\nis useful because bookie startup triggers the addition of the bookie\nnode to zk before the bookie actually becomes available for the bookie\ninfo request, so there can be rare races in the unit tests between\nBookieInfoReader requesting the info and the bookie actually being up.\n\nAlso, add a method to allow tests to wait for updates to be reflected.\n\nPerChannelBookieClient: fix error handling for BookieInfo keys\n\nPassing a key corresponding to a GET_BOOKIE_INFO operation to\nerrorOutReadKey results in a casting exception, clean up the invalid\ncalls.\n\nBookKeeperClusterTestCase: add killBookieAndWaitForZK\n\nShould reduce the need for tests to wait for an arbitrary period to let\nthe cluster \"settle\".\n\nBookKeeperDiskSpaceWeightedLedgerPlacementTest:\n\nThis test was heavily time dependent, and the Thread.sleep values did\nnot work universally.  Instead, eliminate the arbitrary Thread.sleep\nvalues and instead verify the free space changes on each change.\n\nAlso, switch the delay on\ntestDiskSpaceWeightedBookieSelectionWithPeriodicBookieInfoUpdate\nto simply use an atomic boolean to signal the value switch.\n\nSigned-off-by: Samuel Just <sjustsalesforce.com>\n\nAuthor: Samuel Just <sjust@salesforce.com>\n\nReviewers: Enrico Olivelli <eolivelli@gmail.com>\n\nThis patch had conflicts when merged, resolved by\nCommitter: Sijie Guo <sijie@apache.org>\n\nThis closes #275 from athanatos/forupstream/BOOKKEEPER-1102"}, "BOOKKEEPER-1103": {"fixed_bug_sha": "3908d9ce6a5530ae2ae8526b9988b983423c026c", "parent_bug_sha": "fdbea38d9767e6eb28fbf8ec7c61491be3e06e66", "commit_message": "BOOKKEEPER-1103: Fix LedgerMetadataCreateTest random id loop\n\nThe previous version would loop indefinitely upon collision.\n\nSigned-off-by: Samuel Just <sjustsalesforce.com>\n\nAuthor: Samuel Just <sjust@salesforce.com>\n\nReviewers: Enrico Olivelli <eolivelli@gmail.com>, Matteo Merli <mmerli@apache.org>\n\nThis closes #303 from athanatos/forupstream/BOOKKEEPER-1103"}, "BOOKKEEPER-1104": {"fixed_bug_sha": "0ccbc0e9c3e6a82d5e44b8347cc6567e043f253f", "parent_bug_sha": "7a480d3f8e5ec5c8c3592c332cbcab19b4043dad", "commit_message": "BOOKKEEPER-1104: Fix testWithDiskFullAndAbilityToCreateNewIndexFile\n\nThe usage threshhold was chosen to be very close to the actual disk\nusage at test time.  This made the test unnecessarily fragile in the\ncase that there other things concurrently using the disk.  Since we\naren't really testing that here, simply set the threshhold to be really\nlow.\n\nSigned-off-by: Samuel Just <sjustsalesforce.com>\n\nAuthor: Samuel Just <sjust@salesforce.com>\n\nReviewers: Jia Zhai <None>, Matteo Merli <None>\n\nThis closes #310 from athanatos/forupstream/BOOKKEEPER-1104"}, "BOOKKEEPER-1044": {"fixed_bug_sha": "24ac8ead6240aaaaa845afccb4e606fbe0da1602", "parent_bug_sha": "96d82102bef3152934f564db16373b12b1689ead", "commit_message": "BOOKKEEPER-1044: Entrylogger is not readding rolled logs back to the logChannelsToFlush list when exception happens while trying to flush rolled logs\n\nDescriptions of the changes in this PR:\n\nThis is a straightforward fix to add unflushed list of entry log files back to flushed list.\n\nTest is missing at this point because it is a bit complicated to test this without proper mocking. I would defer adding the test later and creating a github issue later on if it makes sense.\n\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Enrico Olivelli <eolivelli@apache.org>\n\nThis closes #286 from sijie/BOOKKEEPER-1044"}, "BOOKKEEPER-1027": {"fixed_bug_sha": "2d992e39da0fc121901a72849b424c86fb099f03", "parent_bug_sha": "11fdac3cfdfe0900db994b45aa17500974ba3907", "commit_message": "BOOKKEEPER-1027: Cleanup README\n\nDescriptions of the changes in this PR:\n\n- Move README to README.md (written it in markdown syntax)\n- Organized the README as below:\n  - what is bookkeeper and what it can be used for\n  - getting started\n  - documentation\n  - contribution\n\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Enrico Olivelli, Jia Zhai\n\nThis closes #248 from sijie/update_readme"}, "BOOKKEEPER-980": {"fixed_bug_sha": "f47dd4272f54bb95fd38abdd6c492dbe199dd7a4", "parent_bug_sha": "d61cfaba69cb0f87bc388889a58f2095f4034f30", "commit_message": "BOOKKEEPER-980: BookKeeper Tools doesn't process the argument correctly\n\nDescriptions of the changes in this PR:\n\nFix the issue described in [BOOKKEEPER-980](https://issues.apache.org/jira/browse/BOOKKEEPER-980).\n\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Matteo Merli <None>, Venkateswararao Jujjuri (JV) <None>\n\nThis closes #255 from sijie/BOOKKEEPER-980"}, "BOOKKEEPER-1106": {"fixed_bug_sha": "2bbecd7da52824c991e1a28573ccf8c8515ea5dd", "parent_bug_sha": "80b7676045c34f4678f754f7f78d77c156ba518d", "commit_message": "BOOKKEEPER-1106: Introduce write FileInfo cache and read FileInfo cache\n\nProblem: when read behind happens, it would quickly read bunch of ledgers, which will evict current active ledgers for writing from the ledger cache. with the ledger being evicted from cache, it would impact the write performance.\n\nThis feature is contributed by sijie , in which we introduced write file info cache and read file info cache to cache the ledger index separately for read and write, so that when catch up read happens, it will not evict the file info for writes.\n\nAuthor: Yiming Zang <yzang@twitter.com>\n\nReviewers: Enrico Olivelli <eolivelli@apache.org>, Jia Zhai\n\nThis closes #513 from yzang/yzang/BOOKKEEPER-1106"}, "BOOKKEEPER-1105": {"fixed_bug_sha": "f5d2ba66d6253fb54811d3ceb40d4ef4591dfb20", "parent_bug_sha": "de9eecc180cc78fb65b509d7ae0e5ea82fd5dc8c", "commit_message": "BOOKKEEPER-1105: RackAwarePolicy: Failure to map node into rack may result in failure to add other nodes.\n\n- RackAwarePolicy's no longer uses /default-region if rack mapping fails unless required (by RegionAwarePolicy)\n- it no longer fails to add rest of nodes after one node's failed addition,\n- added unit tests\n- added counters for successful/failed bookie adds/removal\n(PR description content here)...\n\nUpdateLedgerOpTest failed but it seems to be known/unrelated issue.\n\nAuthor: Andrey Yegorov <ayegorov@salesforce.com>\n\nReviewers: Sijie Guo <sijie@apache.org>\n\nThis closes #425 from dlg99/fix/rackaware"}, "BOOKKEEPER-391": {"fixed_bug_sha": "667390d1a6305c31608130929ba0d68a0b5a4763", "parent_bug_sha": "7da9ed293db87103efcc28b7e706c0b386131ec1", "commit_message": "BOOKKEEPER-391: Support Kerberos authentication of bookkeeper\n\nThis patch contains a very basic AuthProvider which uses JAAS and so enables the usage or GSSAPI/Kerberos for BookKeeper authentication\n\nAuthor: eolivelli <eolivelli@apache.org>\nAuthor: eolivelli <eolivelli@gmail.com>\n\nReviewers: Robert (Bobby) Evans <None>, Sijie Guo <None>\n\nCloses #110 from eolivelli/BOOKKEEPER-391-kerberos"}, "BOOKKEEPER-1069": {"fixed_bug_sha": "e44c7388399e5589cf44e38c58bb84c74da544af", "parent_bug_sha": "0f81461d2d1dc5cf9db4de9a46599d7d64e3dac6", "commit_message": "BOOKKEEPER-1069: If client uses V2 proto, set the connection to always decode V2 messages\n\nAvoid handling parsing exception for each request and instead adapt to what the client is sending.\n\nAuthor: Matteo Merli <mmerli@yahoo-inc.com>\n\nReviewers: Enrico Olivelli <None>, Sijie Guo <None>\n\nCloses #157 from merlimat/always-v2"}, "BOOKKEEPER-1061": {"fixed_bug_sha": "5d43260e84c6121df72c0ee4c844651bfb726638", "parent_bug_sha": "d863513719b696638e3369f4bbfde9abf5fd3d5f", "commit_message": "BOOKKEEPER-1061: BookieWatcher should not do ZK blocking operations from ZK async callback thread\n\nIn some cases, the BookieWatcher can get the ZK event thread stuck. This happens when a ZK blocking request is issued from a ZK callback thread.\n\nWe should decouple the blocking requests in a separate executor to avoid deadlocking ZK client.\n\nAuthor: Matteo Merli <mmerli@apache.org>\n\nReviewers: Jia Zhai <None>, Sijie Guo <sijie@apache.org>\n\nCloses #149 from merlimat/bookie-watcher-thread"}, "BOOKKEEPER-1058": {"fixed_bug_sha": "811ece53a1c975c4e768422f3d622ac9de6b3e41", "parent_bug_sha": "5130d3596f7fb862e38910bf0a0a1dae3ed892e8", "commit_message": "BOOKKEEPER-1058: Ignore already deleted ledger on replication audit\n\nReplication auditor should skip ledgers that were deleted since the auditing was started.\n\nAuthor: rdhabalia <rdhabalia@yahoo-inc.com>\n\nReviewers: Enrico Olivelli <eolivelli@gmail.com>, Sijie Guo <sijie@apache.org>\n\nCloses #146 from merlimat/ignore-deleted-ledgers-in-replication"}, "BOOKKEEPER-1047": {"fixed_bug_sha": "d5af77c05256d5942c19aff2654c5d8f5ac1eb79", "parent_bug_sha": "25c113f62a40bff6ff91cf82f699fd1d35b102fb", "commit_message": "BOOKKEEPER-1047: Add missing error code in ZK setData return path\n\nThe log warning is not printing the error code returned by ZooKeeper\n\nAuthor: Matteo Merli <mmerli@apache.org>\n\nReviewers: Enrico Olivelli <eolivelli@apache.org>\n\nCloses #137 from merlimat/missing-error-msg"}, "BOOKKEEPER-1018": {"fixed_bug_sha": "f74d07d6b96ba3e6f1270d053fa36676cf680304", "parent_bug_sha": "24fae0322327d8fd75c30524546924f27e278448", "commit_message": "BOOKKEEPER-1018: Allow client to select older V2 protocol (no protobuf)\n\nTested manually - running all tests locally. Will tag contributors. when ready for review (for now putting up to test via Screwdriver and manual review)\n\nAuthor: Govind Menon <govindappumenon@gmail.com>\n\nReviewers: Enrico Olivelli <eolivelli@gmail.com>, Sijie Guo <sijie@apache.org>\n\nCloses #126 from govind-menon/BOOKKEEPER-1018"}, "BOOKKEEPER-1040": {"fixed_bug_sha": "3392beee5c70abe36d36604723e14d97b7764be9", "parent_bug_sha": "0ae8abc354c4c7706232aabf474ea37afea90fc2", "commit_message": "BOOKKEEPER-1040: Use separate log for compaction and add transaction support\n\nProblem:\nCompaction might keep generating duplicated data which would cause disk full.\nThis is because we don't have transactional operation for compaction. So if compaction\nkeeps failing in the middle, bookie would end up with a lot of garbage data.\n\nChange:\n1. Introduce abstract class AbstractLogCompactor with an interface compact().\n2. Move the existing compaction logic to a separate class called EntryLogCompactor.\n3. Introduce transactional compaction, we can recover an incomplete compaction or rollback a compaction failure.\n4. Add an configuration to enable transactional compaction\n\nPotential Risk:\n1. No risk if we keep using the default compactor.\n2. If we choose to enable transactional compaction with separate log file, we need to be careful about it, since we use a separate log for compaction, if we have a lot of old small ledgers in the bookie, we will end up with a lot of small entry log files. And this will potentially cause bookkeeper \"Too many open files\" because GC will scan all the entry log files and keep them open.\n\nAuthor: Yiming Zang <yzang@twitter.com>\n\nReviewers: Enrico Olivelli <eolivelli@gmail.com>, Jia Zhai <None>, Sijie Guo <sijie@apache.org>\n\nThis closes #704 from yzang/yzang/BOOKKEEPER-1040"}, "BOOKKEEPER-989": {"fixed_bug_sha": "55d1dc45c4761f150c59a34b94d21e39e69f872c", "parent_bug_sha": "5c81acaccfb0cb1260acdfd7d0bb95ae84f85654", "commit_message": "BOOKKEEPER-989: Enable Travis CI for Apache BookKeeper\n\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Enrico Olivelli <eolivelli@gmail.com>, Jia Zhai <None>, Matteo Merli <mmerli@apache.org>\n\nCloses #168 from sijie/enable_travis_ci"}, "BOOKKEEPER-1074": {"fixed_bug_sha": "dd08ce1a644de00967dd5fe34ce15caa9789d775", "parent_bug_sha": "d1f37dafbb475d4d6aab4769335550428c680269", "commit_message": "BOOKKEEPER-1074: Remove JMX Bean\n\nThis change is based on #160 , the change here is: gitsha [b3be81f](https://github.com/sijie/bookkeeper/commit/b3be81fadae50f2d4a2e938c2735fa35c6c31421)\n\nAuthor: Sijie Guo <sijie@apache.org>\nAuthor: Sijie Guo <sijieg@twitter.com>\n\nReviewers: Enrico Olivelli, Matteo Merli\n\nCloses #161 from sijie/remove_jmx_beam"}, "BOOKKEEPER-1071": {"fixed_bug_sha": "da70648719679fd1db001c74ad873bf134f16198", "parent_bug_sha": "fc51f73cbc9cdaae9876bc08cafa3e7a80826207", "commit_message": "BOOKKEEPER-1071: Use per connection instances of request encoder/decoder\n\nAuthor: Matteo Merli <mmerli@yahoo-inc.com>\n\nReviewers: Enrico Olivelli, Sijie Guo\n\nCloses #170 from merlimat/bk-1071"}, "BOOKKEEPER-1073": {"fixed_bug_sha": "fc51f73cbc9cdaae9876bc08cafa3e7a80826207", "parent_bug_sha": "9bade929dd87829a8903e402f6c3e3be366a854a", "commit_message": "BOOKKEEPER-1073: Several stats provider related changes.\n\n- add finagle stats provider\n- provide the ability to remove gauge and scopes\n- update jetty versions for twitter-sciences stats provider\n\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Jia Zhai, Enrico Olivelli\n\nCloses #160 from sijie/add_channel_writer_timer"}, "BOOKKEEPER-1079": {"fixed_bug_sha": "9bade929dd87829a8903e402f6c3e3be366a854a", "parent_bug_sha": "fd3331a2769a29c379ed63e21ed2dc3c0f85ba25", "commit_message": "BOOKKEEPER-1079: shell lastMark throws NPE\n\nAuthor: Enrico Olivelli <eolivelli@apache.org>\n\nReviewers: Sijie Guo\n\nCloses #167 from eolivelli/BOOKKEEPER-1079"}, "BOOKKEEPER-1077": {"fixed_bug_sha": "6698912e4d35119a2e85a6ea3877c6771073489c", "parent_bug_sha": "64bedc2f92d5bb17783c6ea2a2db7ea29170f264", "commit_message": "BOOKKEEPER-1077: Allow configuration journal/ledger paths for local bookkeeper.\n\nAuthor: Sijie Guo <sijieg@twitter.com>\nAuthor: Robin Dhamankar <rdhamankar@twitter.com>\n\nReviewers: Enrico Olivelli <eolivelli@apache.org>\n\nCloses #163 from sijie/to_string_mark"}, "BOOKKEEPER-1075": {"fixed_bug_sha": "64bedc2f92d5bb17783c6ea2a2db7ea29170f264", "parent_bug_sha": "7b1eec47092d0de6776c5a89575dbfc678165ee7", "commit_message": "BOOKKEEPER-1075: BK LedgerMetadata: more memory-efficient parsing of configs\n\nIt is the contribution from Alex Yarmula\n\ncommit 9d9d7dd26235a9beda4421b7bed750fea1789076\nAuthor: Alex Yarmula <aktwitter.com>\nDate: Wed Sep 23 05:57:30 2015 -0700\n\nBK LedgerMetadata: more memory-efficient parsing of configs\nLooking at the most prevalent client-side memory allocations, I noticed that we allocate 4KB every time we open a ledger. This is caused by allocating a 4KB buffer (in TextFormat.toStringBuilder) to account for the maximum possible Protobufs message, which is unnecessary in our case: we know the exact size of the metadata ( << 500 B) and don't need to allocate more.\nTextFormat.merge(Readable, Message.Builder) is the current method we use. This changes to use TextFormat.merge(CharSequence, Message.Builder), which avoids the extra 4K allocation conversion + an extra StringBuilder.\n\nRB_ID=745700\n\nAuthor: Alex Yarmula <ak@twitter.com>\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Enrico Olivelli, Sijie Guo\n\nCloses #162 from sijie/bk_ledger_metadata_efficiency"}, "BOOKKEEPER-1072": {"fixed_bug_sha": "8ba8ab9403dbc464c68caf6e7cd3fc490670731e", "parent_bug_sha": "667390d1a6305c31608130929ba0d68a0b5a4763", "commit_message": "BOOKKKEEPER-1072: CompactionTest is flaky when disks are almost full\n\nAuthor: Sijie Guo <sijie@apache.org>\n\nReviewers: Enrico Olivelli <None>, Jia Zhai <None>\n\nCloses #159 from sijie/BOOKKEEPER-1072"}, "BOOKKEEPER-365": {"fixed_bug_sha": "e6a2a13876fe676b8fcafa56c3568ea450ad5f67", "parent_bug_sha": "9d09a9c2a64b745271ef1c6dad9e5ab3ab3f2a5c", "commit_message": "ISSUE #1067: PendingReadOp: recovery, return NoSuchEntry on wQ-aQ+1 errors\n\nIn the case of a recovery read, we rely on a NoSuchEntry response on the\nfirst missing entry to determine the final LAC.  As such, we need to\nconsider an entry to be gone once we see wQ-aQ+1 NoSuchEntry/Ledger\nresponses from bookies.  Otherwise, a zombie bookie can prevent ledger\nrecovery from suceeding indefinitely (it'll hit the timeout each time).\n\nThere was some preexisting logic from\nhttps://issues.apache.org/jira/browse/BOOKKEEPER-365\nb6c1a8bbd7c2d44c2edb59d9938fa073f6f478de,\nbut it seems to have been too conservative in that it waited for all\nresponses and required that there were no other errors present.  It\nseems now to be unnecessary, and so has been removed.\n\nTestParallelRead.testFailParallelReadMissingEntryImmediately seemed to\nrely on the previous logic working outside of recovery, but I believe it\nwas really meant to test the recovery case, so it has been adjusted.\n\n(bug W-4651456)\nSigned-off-by: Samuel Just <sjustsalesforce.com>\n\nAuthor: Samuel Just <sjust@salesforce.com>\n\nReviewers: Samuel Just <sjust@salesforce.com>, Ivan Kelly <ivank@apache.org>, Sijie Guo <sijie@apache.org>, Venkateswararao Jujjuri (JV) <None>\n\nThis closes #1077 from athanatos/forupstream/wip-4651456-recovery-read, closes #1067"}, "BOOKKEEPER-1009": {"fixed_bug_sha": "4578e6d65a304c870fcba013099badd6018c95de", "parent_bug_sha": "e20bb40ddff4c5bd033625dc82788b545f8d66ee", "commit_message": "Fixed Journal stats names\n\nIn `BOOKKEEPER-1009: Use multiple journals in bookie` 123eccd435a4a96a9147ed4a24efbe9025fe79ba there was a change in the metrics name that would be affecting also user not running with multiple journal.\n\nIt is a bit inconvenient to aggregate the stats in the metrics collector (how to aggregate 99pct latency for example).\n\nI think the best option is to have a single metric even when using multiple journal threads.\n\nAuthor: Matteo Merli <mmerli@apache.org>\n\nReviewers: Ivan Kelly <ivank@apache.org>, Enrico Olivelli <eolivelli@gmail.com>, Sijie Guo <sijie@apache.org>\n\nThis closes #1250 from merlimat/journal-metric-names"}}}]